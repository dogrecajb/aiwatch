insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
    (
        'https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really#rwCRLwqywjN4Eu3E7', /* url */
        'Comment on After one year of applying for EA jobs: It is really, really hard to get hired by an EA organisation', /* title */
        '2019-02-27', /* publication_date */
        NULL, /* modified_date */
        'Aaron Gertler', /* author */
        'Effective Altruism Forum', /* publisher */
        'Centre for Effective Altruism|Open Philanthropy Project|Machine Intelligence Research Institute|Ought|Vox|AI Impacts|Center for Human-Compatible AI|Berkeley Existential Risk Initiative', /* affected_organizations */
        NULL, /* affected_people */
        'Job application experience', /* document_scope */
        'Various', /* cause_area */
        'Gertler describes his experience applying to various effective altruism-related organizations.' /* notes */
    )
    ,(
        'https://www.facebook.com/bshlgrs/posts/10215867821943197', /* url */
        'I think that every EA who is a software engineer …', /* title */
        '2019-02-27', /* publication_date */
        NULL, /* modified_date */
        'Buck Shlegeris', /* author */
        'Facebook', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Shlegeris encourages effective altruist software engineers to apply to work at MIRI. The post also mentions that the first stage of the interview is the Triplebyte quiz.' /* notes */
    )
    ,(
        'https://www.facebook.com/bshlgrs/posts/10215832806467832', /* url */
        'MIRI is running a sequence of workshops with the …', /* title */
        '2019-02-22', /* publication_date */
        NULL, /* modified_date */
        'Buck Shlegeris', /* author */
        'Facebook', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Shlegeris encourages people to apply to MIRI’s AI Risk for Computer Scientists workshop.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/3u8oZEEayqqjjZ7Nw/current-ai-safety-roles-for-software-engineers#wyKA2bQgLN4LTKFxk', /* url */
        'Comment on Current AI Safety Roles for Software Engineers', /* title */
        '2018-11-09', /* publication_date */
        NULL, /* modified_date */
        'Buck Shlegeris', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Shlegeris clarifies that MIRI would like to hire “as many people as engineers as possible”, and says MIRI is likely to “end up hiring more like ten” engineers over the next year.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/BScxwSun3K2MgpoNz/question-miri-corrigbility-agenda#o9LDEGTDMv8WNa2WA', /* url */
        'Comment on Question: MIRI Corrigbility Agenda', /* title */
        '2019-03-14', /* publication_date */
        NULL, /* modified_date */
        'Rob Bensinger', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'Bensinger notes some updates that have been made to MIRI’s research guide (which was first published in 2014).' /* notes */
    )
    ,(
        'http://lesswrong.com/lw/mxj/working_at_miri_an_interview_with_malo_bourgon/', /* url */
        'Working at MIRI: An interview with Malo Bourgon', /* title */
        '2015-11-01', /* publication_date */
        NULL, /* modified_date */
        'Sören Mindermann', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'An interview with Malo Bourgon (program management analyst and generalist at MIRI) about MIRI’s current talent needs, how to get involved, application process, and donation vs marginal hires.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/cNPZJn8W8cmhTLgtd/on-the-concept-of-talent-constrained-organizations#Byxt4wZsn9GnCsdnq', /* url */
        'Comment on On the concept of “talent-constrained” organizations', /* title */
        '2014-03-17', /* publication_date */
        NULL, /* modified_date */
        'Eliezer Yudkowsky', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'Yudkowsky weighs in regarding talent constraint. In a reply comment Luke Muehlhauser (executive director of MIRI at the time) also gives his opinion.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/HnC29723hm6kJT7KP/taking-ai-risk-seriously-thoughts-by-critch#eBDZzwqvkJ5xZjDMR', /* url */
        'Comment on “Taking AI Risk Seriously” (thoughts by Critch)', /* title */
        '2018-02-01', /* publication_date */
        NULL, /* modified_date */
        'Matthew Graves', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'Graves (who does recruiting work at MIRI) gives his personal opinion on way to get involved in AI safety.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/WqDGJNtxNMT8fHe37/help-fund-lukeprog-at-siai', /* url */
        'Help Fund Lukeprog at SIAI', /* title */
        '2011-08-24', /* publication_date */
        NULL, /* modified_date */
        'Eliezer Yudkowsky', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'A call for donations specifically so MIRI can hire Luke Muehlhauser.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/6vXArgf9NsYxRYkpS/miri-research-guide', /* url */
        'MIRI Research Guide', /* title */
        '2014-11-07', /* publication_date */
        NULL, /* modified_date */
        'Nate Soares', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'Blog post announcing the publication of a new research guide to help people become involved in MIRI’s AI safety research.' /* notes */
    )
    ,(
        'https://www.lesswrong.com/posts/snzFQJsNYqzPZS2nK/course-recommendations-for-friendliness-researchers', /* url */
        'Course recommendations for Friendliness researchers', /* title */
        '2013-01-09', /* publication_date */
        NULL, /* modified_date */
        'Louie Helm', /* author */
        'LessWrong', /* publisher */
        'Machine Intelligence Research Institute', /* affected_organizations */
        NULL, /* affected_people */
        NULL, /* document_scope */
        'AI safety', /* cause_area */
        'A list of course and textbook recommendations for background material related to AI safety.' /* notes */
    )
;
